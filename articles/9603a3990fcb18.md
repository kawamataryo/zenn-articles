---
title: "LangChainのSummarization ChainでWEBページを要約する時のプラクティス"
emoji: "🦜"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["langchain", "openai", "typescript"]
published: false
---

LangChainを使ってWebページを要約しようと思ったら色々詰まったので備忘録としてまとめます。

📝 動作確認環境
- M1 macOS 12.6
- Node.js 18
- [LangChain 0.0.95](https://www.npmjs.com/package/langchain/v/0.0.95)

# 🚀 完成コード

最初に完成コードから。LangChainを実行してWebページを要約するコード例です。

```ts
import { OpenAI } from "langchain/llms/openai";
import { loadSummarizationChain, LLMChain } from "langchain/chains";
import { PuppeteerWebBaseLoader } from "langchain/document_loaders/web/puppeteer";
import { PromptTemplate } from "langchain/prompts";

const summarization = async (url: string) => {
  // Webページのテキストを取得
  const loader = new PuppeteerWebBaseLoader(url, {
    launchOptions: {
      headless: "new",
      args: ["--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"],
    },
    async evaluate(page) {
      const result = await page.evaluate(() => {
        // 不要な要素を削除
        const scripts = document.body.querySelectorAll("script");
        const noscript = document.body.querySelectorAll("noscript");
        const styles = document.body.querySelectorAll("style");
        const scriptAndStyle = [...scripts,  ...noscript, ...styles,];
        scriptAndStyle.forEach((e) => e.remove());

        // 本文を収集
        const mainElement = document.querySelector('main');
        return  mainElement ? mainElement.innerText : document.body.innerText;
      })
      return result;
    },
  });
  const docs = await loader.loadAndSplit();

  // 要約の実行
  const model = new OpenAI({ openAIApiKey: process.env.OPEN_AI_API_KEY, temperature: 0, modelName: "gpt-3.5-turbo" });
  const prompt = new PromptTemplate({
    template: `以下の文章を要約してください。\n\n---\n"{text}"---\n\n要約:`,
    inputVariables: ["text"],
  });
  const chain = loadSummarizationChain(model, {
    combineMapPrompt: prompt,
    combinePrompt: prompt,
    type: "map_reduce",
  });
  const result = await chain.call({
    input_documents: docs
  });

  console.log(`\n\n🔗 link:\n${url}\n\n📝 summary:\n${result.text}`);
}

(async () => {
  const targetUrl = process.argv[2]
  await summarization(targetUrl);
})()
```

CLI上で要約したいURLを引数に渡して実行すると、以下のように要約結果を出力してくれます。

```sh
$ ts-node index.ts https://note.com/ryo_kawamata/n/n4fc0fa900314

🔗 link:
https://note.com/ryo_kawamata/n/n4fc0fa900314

📝 summary:
消防士から未経験でエンジニアに転職し、1年間働いた後に退職した人物が、自身の経歴や転職の理由、エンジニアとしての経験について語っている。JavaやSpring Bootでの実務経験を通じて、良い設計や型の利点、テストの重要性などを学び、静的型付け言語が好きになった。退職理由は家庭の事情で、リモートワークができる環境を求めた。転職先はクラウド請求管理サービスの会社で、RailsとVue.jsを勉強中。今後は成長し、事業に大きな影響を与える成果を出したいと考えている。
```

# 🛠️ ポイント解説

## PuppeteerWebBaseLoaderで要約ページのテキスト情報のみを種痘
SPAも考慮したWebページのテキスト情報を取得するために、PuppeteerWebBaseLoaderを使っています。ここでのポイントは、`evaluate`で取得したいテキスト情報のみを取得するようにすることです。

PuppeteerWebBaseLoaderのデフォルトでは、ページ情報の取得に`document.body.innerHTML`を使っています。

https://github.com/hwchase17/langchainjs/blob/8ddf206998f323ae2785371a6d0fdfabdf5a7ba2/langchain/src/document_loaders/web/puppeteer.ts#L61-L63

`innerHTML`での取得だと、要約に不要なタグ情報や、インラインスタイル、スクリプト情報も含まれてしまいます。これがトークンの利用数をムダに増やしてしまう原因になります。

`evaluate`をオプションで上書き、スクリプトやスタイル、タグ情報など不要な要素を削除した上で`innerText`で本文を取得することで、不要な情報によって要約結果が歪むことを防ぎ、APIのトークン利用数も節約できます。

```ts
//...
  const loader = new PuppeteerWebBaseLoader(url, {
    launchOptions: {
      headless: "new",
      args: ["--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"],
    },
    async evaluate(page) {
      const result = await page.evaluate(() => {
        // 不要な要素を削除
        const scripts = document.body.querySelectorAll("script");
        const noscript = document.body.querySelectorAll("noscript");
        const styles = document.body.querySelectorAll("style");
        const scriptAndStyle = [...scripts,  ...noscript, ...styles,];
        scriptAndStyle.forEach((e) => e.remove());

        // 本文を収集
        const mainElement = document.querySelector('main');
        return  mainElement ? mainElement.innerText : document.body.innerText;
      })
      return result;
    },
  });
// ...
```

## LoadAndSplitでドキュメントを分割

完成コードではPuppeteerWebBaseLoaderで取得したテキスト情報をOpenAIのAPIに渡す際に、`loadAndSplit`を実行しています。
PuppeteerWebBaseLoaderのドキュメントには、`Load`の方で記載されているので間違える人がいるかもしれませんが（自分😇）、`loadAndSplit`でドキュメントを分割しなければ、Summarization Chain を利用する旨味がありません。

loadでdocsを生成すると、ページ情報が以下のようにひとつのドキュメントとして扱われてしまいます。

```
[
  {
    Document: {
      "pageContent: '消防士からエンジニアへ、そして退職\n...."
    },
    metadata: { ... }
  }
]
```

しかし、loadSplitでdocsを生成すると以下のように、よしなにドキュメントを分割してくれます。

```
[
  {
    Document: {
      "pageContent: '消防士からエンジニアへ、そして退職\n...."
    },
    metadata: { ... }
  },
  {
    Document: {
      "pageContent: '前職では...
    },
    metadata: { ... }
  }
  {
    Document: {
      "pageContent: '筋肉.ktで筋肉を...
    },
    metadata: { ... }
  },
  ....
]
```

とくにページの文章量が多い場合は、ドキュメントを分割しないと、最大トークン数を超過してしまい、Summarization Chainの実行時にエラーが発生します。

```ts
